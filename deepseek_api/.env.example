# DeepSeek R1 Local Configuration

# Base URL for your locally hosted model (e.g., Ollama, vLLM, llama.cpp)
LOCAL_MODEL_URL=http://localhost:11434/v1

# Model name as configured in your local server
MODEL_NAME=deepseek-r1

# Server settings
HOST=0.0.0.0
PORT=8000
